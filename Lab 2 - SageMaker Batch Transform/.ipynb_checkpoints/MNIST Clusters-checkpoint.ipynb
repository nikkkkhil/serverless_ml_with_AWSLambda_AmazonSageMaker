{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Clusters and Batch Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all of the necessary libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boto3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1dc96099ca45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mboto3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamazon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwrite_numpy_to_dense_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'boto3'"
     ]
    }
   ],
   "source": [
    "import pickle, gzip, numpy, json\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import boto3\n",
    "from sagemaker.amazon.common import write_numpy_to_dense_tensor\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace ```your-bucket-name``` with the name of the bucket you created for this workshop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = '<your-bucket-name>' \n",
    "BUCKET_URL = \"s3://\" + BUCKET_NAME\n",
    "TRAIN_VAL_TEST_FOLDER = 'ServerlessAIWorkshop/data'\n",
    "TRAINING_DATA_KEY = TRAIN_VAL_TEST_FOLDER + \"/train.data\"\n",
    "TRAINING_DATA_URL = \"s3://\" + BUCKET_NAME + \"/\" + TRAINING_DATA_KEY\n",
    "TRAINING_DATA_FOLDER = \"s3://\" + BUCKET_NAME + \"/\" + TRAIN_VAL_TEST_FOLDER\n",
    "MODEL_URL = BUCKET_URL + \"/ServerlessAIWorkshop/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset and load it to local variables. Upload the training data to S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Load the dataset\n",
    "urllib.request.urlretrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\", \"mnist.pkl.gz\")\n",
    "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "\n",
    "print('training data will be uploaded to: {}'.format(TRAINING_DATA_URL))\n",
    "\n",
    "boto3.resource('s3').Bucket(BUCKET_NAME).Object(TRAINING_DATA_KEY).upload_fileobj(buf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (2,10)\n",
    "\n",
    "def show_digit(img, caption='', subplot=None):\n",
    "    if subplot == None:\n",
    "        _, (subplot) = plt.subplots(1,1)\n",
    "    imgr = img.reshape((28,28))\n",
    "    subplot.axis('off')\n",
    "    subplot.imshow(imgr, cmap='gray')\n",
    "    plt.title(caption)\n",
    "\n",
    "show_digit(train_set[0][30], 'This is a {}'.format(train_set[1][30]))\n",
    "#plt.savefig(\"test.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SageMaker Python library embodies a number of conventions. It creates subfolders and default destinations for you with conventions you should know. When setting up locations for your work note: \n",
    "\n",
    "* All data must reside in S3, with the possible exception of the initial dataset download. Even that should go directly to S3 if possible.\n",
    "* Training, validation, and testing data should be specified by bucket only. \n",
    "* Model output will go into a directory of the format: \n",
    "    * lad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the training dataset and label to the format required by the SageMaker KMeans algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "buf = io.BytesIO()\n",
    "write_numpy_to_dense_tensor(buf, train_set[0], train_set[1])\n",
    "buf.seek(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize KMeans for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import KMeans\n",
    "\n",
    "kmeans = KMeans(role=role,\n",
    "                train_instance_count=2,\n",
    "                train_instance_type='ml.c4.8xlarge',\n",
    "                output_path=MODEL_URL,\n",
    "                k=10,\n",
    "                data_location=TRAINING_DATA_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model, using the high-level SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "kmeans.fit(kmeans.record_set(train_set[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the path to where the trained model is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.latest_training_job.job_name\n",
    "TRAINED_MODEL_URL = '{}/{}/output/model.tar.gz'.format(MODEL_URL, kmeans.latest_training_job.job_name)\n",
    "TRAINED_MODEL_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "amazon_estimator.get_image_uri() return algorithm image URI for the given AWS region, repository name, and repository version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "sagemaker = boto3.client('sagemaker')\n",
    "\n",
    "image = get_image_uri(boto3.Session().region_name, 'kmeans') #et_image_uri(region_name, repo_name, repo_version=1)\n",
    "\n",
    "kmeans_hosting_container = {\n",
    "    'Image': image,\n",
    "    'ModelDataUrl': TRAINED_MODEL_URL\n",
    "}\n",
    "\n",
    "kmeans_hosting_container # print it out to make sure it is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a SageMaker model from the trained model. This step is necessary as training job that we kicked off in above step does not create a model accessible from batch transform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_response = sagemaker.create_model(\n",
    "    ModelName=kmeans.latest_training_job.job_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer=kmeans_hosting_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
